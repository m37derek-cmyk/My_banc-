import streamlit as st
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

# ==========================================
# 1. CONFIGURATION DE LA PAGE
# ==========================================
st.set_page_config(
    page_title="Pr√©diction Risque Cr√©dit",
    page_icon="üè¶",
    layout="wide"
)

# ==========================================
# 2. CHARGEMENT ET ENTRA√éNEMENT (CACHE)
# ==========================================
@st.cache_resource
def load_and_train_model():
    # --- Gestion robuste du chemin du fichier ---
    current_dir = os.path.dirname(os.path.abspath(__file__))
    file_path = os.path.join(current_dir, "credit_data.csv")

    # --- Chargement des donn√©es ---
    try:
        df = pd.read_csv(file_path)
        df = df.dropna()
    except FileNotFoundError:
        return None, None, None, None, None, f"Erreur : Le fichier est introuvable au chemin : {file_path}"
    except Exception as e:
        return None, None, None, None, None, f"Erreur inattendue : {e}"

    # --- Pr√©paration des variables ---
    if not {'income', 'age', 'loan', 'LTI', 'default'}.issubset(df.columns):
        return None, None, None, None, None, "Erreur : Le fichier CSV ne contient pas les bonnes colonnes."

    X = df[['income', 'age', 'loan', 'LTI']]
    y = df['default']

    # --- S√©paration Train / Test (Pour l'√©valuation) ---
    # On garde 20% des donn√©es pour tester la matrice de confusion
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # --- Standardisation ---
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # --- Entra√Ænement du mod√®le ---
    model = LogisticRegression()
    model.fit(X_train_scaled, y_train)

    # --- Calcul des M√©triques de performance ---
    y_pred = model.predict(X_test_scaled)
    
    acc = accuracy_score(y_test, y_pred)
    cm = confusion_matrix(y_test, y_pred)
    report = classification_report(y_test, y_pred, output_dict=True)

    # On retourne le mod√®le, le scaler, et les m√©triques
    return model, scaler, acc, cm, report, None

# Appel de la fonction
model, scaler, accuracy, cm, report, error_message = load_and_train_model()

# ==========================================
# 3. INTERFACE UTILISATEUR
# ==========================================
st.title("üè¶ Syst√®me de Scoring Cr√©dit (IA)")

# Gestion de l'affichage en cas d'erreur
if error_message:
    st.error(error_message)
    st.stop()

# --- Sidebar : Saisie ---
st.sidebar.header("Param√®tres du Client")

def user_input_features():
    income = st.sidebar.number_input("Revenu Annuel (‚Ç¨)", min_value=1000.0, value=40000.0, step=500.0)
    age = st.sidebar.slider("√Çge", min_value=18, max_value=100, value=30)
    loan = st.sidebar.number_input("Montant du Pr√™t demand√© (‚Ç¨)", min_value=100.0, value=5000.0, step=100.0)
    
    lti = loan / income
    st.sidebar.info(f"Ratio Dette/Revenu (LTI) : {lti:.4f}")
    
    data = {
        'income': income,
        'age': age,
        'loan': loan,
        'LTI': lti
    }
    return pd.DataFrame(data, index=[0])

input_df = user_input_features()

# --- Onglets Principaux ---
tab1, tab2 = st.tabs(["üîÆ Pr√©diction", "üìä Performance du Mod√®le"])

with tab1:
    st.subheader("1. Profil du client")
    st.write(input_df)

    if st.button("Lancer l'analyse du risque"):
        # 1. Standardisation
        input_df_scaled = scaler.transform(input_df)

        # 2. Pr√©diction
        prediction_proba = model.predict_proba(input_df_scaled)
        risque_defaut = prediction_proba[0][1]

        st.subheader("2. R√©sultat de l'analyse")
        
        col1, col2 = st.columns(2)

        with col1:
            st.write("**Probabilit√© de d√©faut :**")
            st.metric(label="Score de Risque", value=f"{risque_defaut:.2%}")
            
            if risque_defaut < 0.2:
                st.progress(risque_defaut)
            elif risque_defaut < 0.5:
                st.progress(risque_defaut)
            else:
                st.progress(risque_defaut)

        with col2:
            st.write("**Recommandation IA :**")
            if risque_defaut > 0.5:
                st.error("‚õî REFUS CONSEILL√â")
                st.write("Le risque de non-remboursement est tr√®s √©lev√©.")
            elif risque_defaut > 0.2:
                st.warning("‚ö†Ô∏è EXAMEN MANUEL REQUIS")
                st.write("Risque mod√©r√©, v√©rifiez les garanties.")
            else:
                st.success("‚úÖ ACCORD CONSEILL√â")
                st.write("Profil fiable et stable.")

with tab2:
    st.header("√âvaluation de la performance")
    st.markdown("Ces m√©triques sont calcul√©es sur un jeu de test (20% des donn√©es) que le mod√®le n'a jamais vu.")

    # Affichage des KPIs
    col_metric1, col_metric2 = st.columns(2)
    col_metric1.metric("Pr√©cision Globale (Accuracy)", f"{accuracy:.2%}")
    col_metric2.metric("Support (Nb de tests)", int(cm.sum()))

    st.markdown("---")
    
    col_graph1, col_graph2 = st.columns(2)

    with col_graph1:
        st.subheader("Matrice de Confusion")
        st.write("Visualisation des bonnes et mauvaises pr√©dictions.")
        
        # Cr√©ation du graphique avec Seaborn
        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax)
        ax.set_xlabel('Predit')
        ax.set_ylabel('R√©el')
        ax.set_xticklabels(['Pay√© (0)', 'D√©faut (1)'])
        ax.set_yticklabels(['Pay√© (0)', 'D√©faut (1)'])
        st.pyplot(fig)

    with col_graph2:
        st.subheader("D√©tails par classe")
        # Transformation du rapport en DataFrame pour un affichage propre
        report_df = pd.DataFrame(report).transpose()
        st.dataframe(report_df.style.format("{:.2f}"))
        
        st.info("""
        **L√©gende :**
        * **Precision** : Quand le mod√®le pr√©dit "D√©faut", a-t-il raison ?
        * **Recall** : Sur tous les vrais "D√©fauts", combien le mod√®le en a-t-il trouv√© ?
        """)
